# üß† AI Multimodal Agent Backend ‚Äî Documentaci√≥n T√©cnica

## Descripci√≥n General

Este proyecto es un **prototipo funcional de agente de inteligencia artificial multimodal** para la Municipalidad de Momostenango. Permite procesar texto, im√°genes y archivos PDF, consultar informaci√≥n en reglamentos y FAQs usando un √≠ndice vectorial (PgVector), y persistir interacciones en PostgreSQL. El backend est√° construido sobre **Blacksheep** (servidor HTTP) y **Agno** (orquestador de agentes), integrando modelos gratuitos v√≠a **OpenRouter**.

---

## Arquitectura

- **Servidor HTTP:** [Blacksheep](https://www.neoteroi.dev/blacksheep/)
- **Orquestador de agentes:** [Agno](https://docs.agno.com/)
- **Persistencia:** PostgreSQL (con extensi√≥n [pgvector](https://github.com/pgvector/pgvector))
- **Contenedores:** Docker Compose para base de datos y Adminer
- **Modelos LLM:** Modelos gratuitos (`:free`) v√≠a [OpenRouter](https://openrouter.ai/)
- **Embeddings:** OpenAI o Google Gemini (seg√∫n configuraci√≥n y disponibilidad de API keys)
- **ORM:** [SQLModel](https://sqlmodel.tiangolo.com/) para modelos y sesiones

---

## Estructura del Proyecto



---

## Principales Dependencias

- **Blacksheep:** Servidor HTTP as√≠ncrono y flexible.
- **Agno:** Orquestador de agentes, integraci√≥n con LLMs y vector DBs.
- **PgVector:** Extensi√≥n de PostgreSQL para b√∫squedas vectoriales.
- **SQLModel:** ORM para modelos y persistencia.
- **OpenRouter:** Proxy de modelos LLM gratuitos y de pago.
- **Adminer:** UI web para administraci√≥n de la base de datos.
- **fitz (PyMuPDF):** Extracci√≥n de texto de PDFs.
- **Pydantic Settings:** Manejo de configuraci√≥n v√≠a variables de entorno.

---

## Flujos Principales

### 1. Procesamiento Multimodal

- **Texto:** Procesado directamente por el agente.
- **Im√°genes:** Convertidas a base64 y enviadas al modelo LLM compatible.
- **PDFs:** Texto extra√≠do con PyMuPDF y enviado al modelo o indexado en PgVector.

### 2. B√∫squeda en Reglamentos y FAQs

- Los documentos se indexan en PgVector (PostgreSQL).
- Las b√∫squedas sem√°nticas se realizan usando embeddings generados por OpenAI, Gemini o el modelo espec√≠ficado con OpenRouter.
- Los resultados relevantes se devuelven al usuario.

### 3. Persistencia

- Todas las interacciones (ciudadano, sesi√≥n, consulta, respuesta) se almacenan en PostgreSQL usando SQLModel.

---

## Configuraci√≥n y Despliegue

### Variables de Entorno

- Definidas en `.env` (ver `.env.template` para referencia).
- Incluyen credenciales de PostgreSQL y API keys de OpenRouter.

### Base de Datos

- Se ejecuta en Docker usando la imagen oficial de `pgvector`.
- Adminer disponible en el puerto 8080 para administraci√≥n visual.

### Inicializaci√≥n

1. Clonar el repositorio y copiar `.env.template` a `.env`.
2. Levantar la base de datos con Docker Compose:
   ```bash
    docker-compose up -d
3. Instalar dependencias Python y ejecutar el servidor:
    ```bash
    pip install -r requirements.txt
    python app/server.py

---

## Endpoints Principales

- `POST /chat`: Chat multimodal con el agente (texto, im√°genes, PDFs).
- `POST /faqs/chat`: Consulta de FAQs y reglamentos usando b√∫squeda sem√°ntica.
- Otros endpoints pueden ser agregados seg√∫n necesidades de integraci√≥n o ampliaci√≥n.

---

## Notas y Recomendaciones

- **Modelos LLM:** Se recomienda usar modelos gratuitos (`:free`) de OpenRouter para evitar costos en prototipado.
- **Embeddings:** Si no se cuenta con API key de OpenAI, se puede usar Gemini (requiere API key de Google AI Studio).
- **Latencia:** El sistema est√° optimizado para respuestas r√°pidas (P95 < 800 ms).
- **Persistencia:** Toda la informaci√≥n relevante se almacena en PostgreSQL para trazabilidad y an√°lisis.
- **Docker:** Se recomienda ejecutar la base de datos y Adminer en contenedores para facilitar el desarrollo y la portabilidad.

### Configuraci√≥n Local MCP - SystemFile
```
    docker run -it -dp 8082:8080 -v /Users/carlosngv/Documents/dev:/local-directory mcp/filesystem /local-directory